{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import required libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer, BertModel, AdamW\n",
    "import random\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=r'C:\\Users\\DELL\\Documents\\ML4SCI\\model_gen-algo_weights'\n",
    "os.makedirs(output_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78, 2), (9, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=torch.load(r'C:\\Users\\DELL\\Documents\\ML4SCI\\tokenized_train.pt')\n",
    "val_data=torch.load(r'C:\\Users\\DELL\\Documents\\ML4SCI\\tokenized_val.pt')\n",
    "train_data.shape,val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data.reset_index(drop=True)\n",
    "val_data=val_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "POPULATION_SIZE = 15\n",
    "GENERATIONS = 100\n",
    "MUTATION_RATE = 0.1\n",
    "tokenizer=BertTokenizer.from_pretrained(r'C:\\Users\\DELL\\Documents\\ML4SCI\\basic-bert-tokenizer')\n",
    "bert=BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": false,
    "execution": {
     "execution_failed": "2025-03-17T07:43:47.010Z"
    },
    "id": "i4lh72MyyF6-",
    "outputId": "8acab45f-119c-48b7-e775-37fe94b0619a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1, Best Fitness score : 3.8364491727617054\n",
      "Saved weights at step 1\n",
      "Generation 2, Best Fitness score : 3.8324600325690374\n",
      "Generation 3, Best Fitness score : 3.8324600325690374\n",
      "Generation 4, Best Fitness score : 3.8286254670884876\n",
      "Generation 5, Best Fitness score : 3.8251503573523626\n",
      "Generation 6, Best Fitness score : 3.8251503573523626\n",
      "Saved weights at step 6\n",
      "Generation 7, Best Fitness score : 3.8251503573523626\n",
      "Generation 8, Best Fitness score : 3.8251503573523626\n",
      "Generation 9, Best Fitness score : 3.8238841427697077\n",
      "Generation 10, Best Fitness score : 3.8238841427697077\n",
      "Generation 11, Best Fitness score : 3.8238841427697077\n",
      "Saved weights at step 11\n",
      "Generation 12, Best Fitness score : 3.823054472605387\n",
      "Generation 13, Best Fitness score : 3.823054472605387\n",
      "Generation 14, Best Fitness score : 3.823054472605387\n",
      "Generation 15, Best Fitness score : 3.823054472605387\n",
      "Generation 16, Best Fitness score : 3.8219240771399603\n",
      "Saved weights at step 16\n",
      "Generation 17, Best Fitness score : 3.8219240771399603\n",
      "Generation 18, Best Fitness score : 3.8219240771399603\n",
      "Generation 19, Best Fitness score : 3.8219240771399603\n",
      "Generation 20, Best Fitness score : 3.8219240771399603\n",
      "Generation 21, Best Fitness score : 3.8219240771399603\n",
      "Saved weights at step 21\n",
      "Generation 22, Best Fitness score : 3.8185941908094616\n",
      "Generation 23, Best Fitness score : 3.8185941908094616\n",
      "Generation 24, Best Fitness score : 3.8185941908094616\n",
      "Generation 25, Best Fitness score : 3.8185941908094616\n",
      "Generation 26, Best Fitness score : 3.8185941908094616\n",
      "Saved weights at step 26\n",
      "Generation 27, Best Fitness score : 3.8185941908094616\n",
      "Generation 28, Best Fitness score : 3.8185941908094616\n",
      "Generation 29, Best Fitness score : 3.8185941908094616\n",
      "Generation 30, Best Fitness score : 3.817350149154663\n",
      "Generation 31, Best Fitness score : 3.817350149154663\n",
      "Saved weights at step 31\n",
      "Generation 32, Best Fitness score : 3.817350149154663\n",
      "Generation 33, Best Fitness score : 3.817350149154663\n",
      "Generation 34, Best Fitness score : 3.817350149154663\n",
      "Generation 35, Best Fitness score : 3.817350149154663\n",
      "Generation 36, Best Fitness score : 3.817350149154663\n",
      "Saved weights at step 36\n",
      "Generation 37, Best Fitness score : 3.817350149154663\n",
      "Generation 38, Best Fitness score : 3.817350149154663\n",
      "Generation 39, Best Fitness score : 3.817350149154663\n",
      "Generation 40, Best Fitness score : 3.817350149154663\n",
      "Generation 41, Best Fitness score : 3.817350149154663\n",
      "Saved weights at step 41\n",
      "Generation 42, Best Fitness score : 3.817350149154663\n",
      "Generation 43, Best Fitness score : 3.817350149154663\n",
      "Generation 44, Best Fitness score : 3.817350149154663\n",
      "Generation 45, Best Fitness score : 3.817350149154663\n",
      "Generation 46, Best Fitness score : 3.817350149154663\n",
      "Saved weights at step 46\n",
      "Generation 47, Best Fitness score : 3.817350149154663\n",
      "Generation 48, Best Fitness score : 3.817350149154663\n",
      "Generation 49, Best Fitness score : 3.817350149154663\n",
      "Generation 50, Best Fitness score : 3.817350149154663\n",
      "Generation 51, Best Fitness score : 3.817350149154663\n",
      "Saved weights at step 51\n",
      "Generation 52, Best Fitness score : 3.8162719938490124\n",
      "Generation 53, Best Fitness score : 3.8162719938490124\n",
      "Generation 54, Best Fitness score : 3.8162719938490124\n",
      "Generation 55, Best Fitness score : 3.8162719938490124\n",
      "Generation 56, Best Fitness score : 3.8162719938490124\n",
      "Saved weights at step 56\n",
      "Generation 57, Best Fitness score : 3.8162719938490124\n",
      "Generation 58, Best Fitness score : 3.8162719938490124\n",
      "Generation 59, Best Fitness score : 3.8162719938490124\n",
      "Generation 60, Best Fitness score : 3.8162719938490124\n",
      "Generation 61, Best Fitness score : 3.8162719938490124\n",
      "Saved weights at step 61\n",
      "Generation 62, Best Fitness score : 3.8162719938490124\n",
      "Generation 63, Best Fitness score : 3.8162719938490124\n",
      "Generation 64, Best Fitness score : 3.8162719938490124\n",
      "Generation 65, Best Fitness score : 3.8162719938490124\n",
      "Generation 66, Best Fitness score : 3.8162719938490124\n",
      "Saved weights at step 66\n",
      "Generation 67, Best Fitness score : 3.8162719938490124\n",
      "Generation 68, Best Fitness score : 3.8162719938490124\n",
      "Generation 69, Best Fitness score : 3.8162719938490124\n",
      "Generation 70, Best Fitness score : 3.8162719938490124\n",
      "Generation 71, Best Fitness score : 3.8162719938490124\n",
      "Saved weights at step 71\n",
      "Generation 72, Best Fitness score : 3.8162719938490124\n",
      "Generation 73, Best Fitness score : 3.8162719938490124\n",
      "Generation 74, Best Fitness score : 3.8162719938490124\n",
      "Generation 75, Best Fitness score : 3.8162719938490124\n",
      "Generation 76, Best Fitness score : 3.8162719938490124\n",
      "Saved weights at step 76\n",
      "Generation 77, Best Fitness score : 3.8162719938490124\n",
      "Generation 78, Best Fitness score : 3.8162719938490124\n",
      "Generation 79, Best Fitness score : 3.8162719938490124\n",
      "Generation 80, Best Fitness score : 3.815500126944648\n",
      "Generation 81, Best Fitness score : 3.815500126944648\n",
      "Saved weights at step 81\n",
      "Generation 82, Best Fitness score : 3.815500126944648\n",
      "Generation 83, Best Fitness score : 3.815500126944648\n",
      "Generation 84, Best Fitness score : 3.815500126944648\n",
      "Generation 85, Best Fitness score : 3.815500126944648\n",
      "Generation 86, Best Fitness score : 3.815500126944648\n",
      "Saved weights at step 86\n",
      "Generation 87, Best Fitness score : 3.815500126944648\n",
      "Generation 88, Best Fitness score : 3.815500126944648\n",
      "Generation 89, Best Fitness score : 3.815500126944648\n",
      "Generation 90, Best Fitness score : 3.815500126944648\n",
      "Generation 91, Best Fitness score : 3.815500126944648\n",
      "Saved weights at step 91\n",
      "Generation 92, Best Fitness score : 3.815500126944648\n",
      "Generation 93, Best Fitness score : 3.815500126944648\n",
      "Generation 94, Best Fitness score : 3.815500126944648\n",
      "Generation 95, Best Fitness score : 3.815500126944648\n",
      "Generation 96, Best Fitness score : 3.815500126944648\n",
      "Saved weights at step 96\n",
      "Generation 97, Best Fitness score : 3.815500126944648\n",
      "Generation 98, Best Fitness score : 3.815500126944648\n",
      "Generation 99, Best Fitness score : 3.8128372298346624\n",
      "Generation 100, Best Fitness score : 3.8128372298346624\n",
      "Best parameter : {'learning_rate': 0.003849405145532908}\n"
     ]
    }
   ],
   "source": [
    "class TranformerModel(nn.Module):\n",
    "    def __init__(self,bert_model,vocab_size):\n",
    "        super(TranformerModel,self).__init__()\n",
    "        self.bert=bert_model\n",
    "        self.decoder=nn.Linear(768,vocab_size)\n",
    "        \n",
    "    def forward(self,input_ids,attention_mask):\n",
    "        outputs=self.bert(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        last_hidden_state=outputs.last_hidden_state\n",
    "        logits=self.decoder(last_hidden_state)\n",
    "        return logits\n",
    "    \n",
    "def initialize_population(population_size):\n",
    "    population=[]\n",
    "    for _ in range(population_size):\n",
    "        learning_rate=10**random.uniform(-7,-1)\n",
    "        population.append({'learning_rate':learning_rate})\n",
    "    return population\n",
    "\n",
    "def fitness(individual,model,train_data,val_data,device):\n",
    "    train_inputs=list(train_data['Features'].values)\n",
    "    train_outputs=list(train_data['Targets'].values)\n",
    "    val_inputs=list(val_data['Features'].values)\n",
    "    val_outputs=list(val_data['Targets'].values)\n",
    "    \n",
    "    model=TranformerModel(bert,tokenizer.vocab_size).to(device)\n",
    "    optimizer=AdamW(model.parameters(),lr=individual['learning_rate'])\n",
    "    criterion=nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "    model.train()\n",
    "    \n",
    "    for i in range(len(train_inputs)):\n",
    "        train_input_ids=train_inputs[i]['input_ids'].to(device)\n",
    "        train_attention_mask=train_inputs[i]['attention_mask'].to(device)\n",
    "        train_output_ids=train_outputs[i]['input_ids'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits=model(train_input_ids,train_attention_mask)\n",
    "        loss=criterion(logits.view(-1,logits.size(-1)),train_output_ids.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss=0\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(val_inputs)):\n",
    "            val_input_ids=val_inputs[i]['input_ids'].to(device)\n",
    "            val_attention_mask=val_inputs[i]['attention_mask'].to(device)\n",
    "            val_output_ids=val_outputs[i]['input_ids'].to(device)\n",
    "            \n",
    "            logits=model(val_input_ids,val_attention_mask)\n",
    "            loss=criterion(logits.view(-1,logits.size(-1)),val_output_ids.view(-1))\n",
    "            val_loss+=loss.item()\n",
    "        \n",
    "        avg_loss=val_loss/len(val_inputs)\n",
    "        return avg_loss\n",
    "    \n",
    "def selection(population,fitness_scores):\n",
    "    sorted_population=[p for _,p in sorted(zip(fitness_scores,population))]\n",
    "    num_parents=len(population)//2\n",
    "    if num_parents==0  and len(population)>0:\n",
    "        return [population[0]]\n",
    "    return sorted_population[:num_parents]\n",
    "\n",
    "def cross_over(parents):\n",
    "    children=[]\n",
    "    for i in range(len(parents),2):\n",
    "        if i+1<len(parents):\n",
    "            parent1=parents[i]\n",
    "            parent2=parents[i+1]\n",
    "            child1={'learning_rate':(parent1['learning_rate']+parent2['learning_rate'])/2}\n",
    "            child2={'learning_rate':(parent1['learning_rate']+parent2['learning_rate'])/2}\n",
    "            children.extend([child1,child2])\n",
    "    return children\n",
    "\n",
    "def mutate(individual,mutation_rate):\n",
    "    if random.random()<mutation_rate:\n",
    "        individual['learning_rate']*=10**random.uniform(-0.5,0.5)\n",
    "    return individual\n",
    "\n",
    "def genetic_algorithm(model,train_data,val_data,device):\n",
    "    population=initialize_population(POPULATION_SIZE)\n",
    "    best_individual=None\n",
    "    best_fitness=float('inf')\n",
    "    \n",
    "    for generation in range(GENERATIONS):\n",
    "        fitness_scores=[fitness(individual,model,train_data,val_data,device) for individual in population]\n",
    "        \n",
    "        if min(fitness_scores)<best_fitness:\n",
    "            best_fitness=min(fitness_scores)\n",
    "            best_individual=population[fitness_scores.index(min(fitness_scores))]\n",
    "            \n",
    "        print(f'Generation {generation+1}, Best Fitness score : {best_fitness}')\n",
    "        if generation%5==0:\n",
    "            weights_path=os.path.join(output_dir,f'weights_step_{generation+1}.pth')\n",
    "            torch.save(model.state_dict(),weights_path)\n",
    "            print(f'Saved weights at step {generation+1}')\n",
    "            \n",
    "        parents=selection(population,fitness_scores)\n",
    "        children=cross_over(parents)\n",
    "        mutated=[mutate(child,MUTATION_RATE) for child in children]\n",
    "        population=parents+mutated\n",
    "        \n",
    "    return best_individual\n",
    "\n",
    "best_parameter=genetic_algorithm(bert,train_data,val_data,device)\n",
    "\n",
    "print('Best parameter :', best_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :0----> Train_loss :4.65470\n",
      "Saved weights at step 1\n",
      "              Validation_loss :3.81999\n",
      "Epoch :1----> Train_loss :3.56730\n",
      "              Validation_loss :3.79237\n",
      "Epoch :2----> Train_loss :3.52157\n",
      "              Validation_loss :3.80559\n",
      "Epoch :3----> Train_loss :3.50704\n",
      "              Validation_loss :3.81196\n",
      "Epoch :4----> Train_loss :3.49577\n",
      "              Validation_loss :3.80949\n",
      "Epoch :5----> Train_loss :3.48544\n",
      "              Validation_loss :3.80327\n",
      "Epoch :6----> Train_loss :3.47463\n",
      "              Validation_loss :3.80229\n",
      "Epoch :7----> Train_loss :3.47286\n",
      "              Validation_loss :3.78951\n",
      "Epoch :8----> Train_loss :3.46633\n",
      "              Validation_loss :3.78267\n",
      "Epoch :9----> Train_loss :3.45782\n",
      "              Validation_loss :3.81319\n",
      "Epoch :10----> Train_loss :3.45928\n",
      "              Validation_loss :3.83287\n",
      "Epoch :11----> Train_loss :3.45834\n",
      "              Validation_loss :3.81172\n",
      "Epoch :12----> Train_loss :3.45317\n",
      "              Validation_loss :3.80009\n",
      "Epoch :13----> Train_loss :3.44824\n",
      "              Validation_loss :3.79296\n",
      "Epoch :14----> Train_loss :3.44448\n",
      "              Validation_loss :3.80016\n",
      "Epoch :15----> Train_loss :3.44476\n",
      "              Validation_loss :3.81321\n",
      "Epoch :16----> Train_loss :3.44550\n",
      "              Validation_loss :3.80981\n",
      "Epoch :17----> Train_loss :3.44356\n",
      "              Validation_loss :3.81600\n",
      "Epoch :18----> Train_loss :3.44270\n",
      "              Validation_loss :3.80303\n",
      "Epoch :19----> Train_loss :3.44063\n",
      "              Validation_loss :3.79534\n",
      "Epoch :20----> Train_loss :3.44085\n",
      "              Validation_loss :3.79553\n",
      "Epoch :21----> Train_loss :3.43517\n",
      "              Validation_loss :3.82513\n",
      "Epoch :22----> Train_loss :3.43651\n",
      "              Validation_loss :3.83289\n",
      "Epoch :23----> Train_loss :3.44083\n",
      "              Validation_loss :3.80604\n",
      "Epoch :24----> Train_loss :3.43547\n",
      "              Validation_loss :3.81349\n",
      "Epoch :25----> Train_loss :3.43646\n",
      "              Validation_loss :3.80268\n",
      "Epoch :26----> Train_loss :3.43341\n",
      "              Validation_loss :3.79279\n",
      "Epoch :27----> Train_loss :3.43138\n",
      "              Validation_loss :3.82496\n",
      "Epoch :28----> Train_loss :3.43337\n",
      "              Validation_loss :3.81779\n",
      "Epoch :29----> Train_loss :3.43342\n",
      "              Validation_loss :3.80570\n",
      "Epoch :30----> Train_loss :3.43183\n",
      "              Validation_loss :3.80467\n",
      "Epoch :31----> Train_loss :3.43131\n",
      "              Validation_loss :3.80410\n",
      "Epoch :32----> Train_loss :3.42871\n",
      "              Validation_loss :3.81391\n",
      "Epoch :33----> Train_loss :3.42871\n",
      "              Validation_loss :3.82436\n",
      "Epoch :34----> Train_loss :3.42593\n",
      "              Validation_loss :3.82659\n",
      "Epoch :35----> Train_loss :3.42884\n",
      "              Validation_loss :3.82121\n",
      "Epoch :36----> Train_loss :3.43633\n",
      "              Validation_loss :3.79541\n",
      "Epoch :37----> Train_loss :3.42881\n",
      "              Validation_loss :3.79633\n",
      "Epoch :38----> Train_loss :3.42398\n",
      "              Validation_loss :3.83780\n",
      "Epoch :39----> Train_loss :3.42975\n",
      "              Validation_loss :3.81251\n",
      "Epoch :40----> Train_loss :3.42083\n",
      "              Validation_loss :3.81488\n",
      "Epoch :41----> Train_loss :3.42570\n",
      "              Validation_loss :3.81000\n",
      "Epoch :42----> Train_loss :3.43058\n",
      "              Validation_loss :3.78875\n",
      "Epoch :43----> Train_loss :3.41701\n",
      "              Validation_loss :3.82810\n",
      "Epoch :44----> Train_loss :3.42151\n",
      "              Validation_loss :3.81977\n",
      "Epoch :45----> Train_loss :3.42341\n",
      "              Validation_loss :3.81073\n",
      "Epoch :46----> Train_loss :3.42016\n",
      "              Validation_loss :3.81763\n",
      "Epoch :47----> Train_loss :3.42575\n",
      "              Validation_loss :3.79360\n",
      "Epoch :48----> Train_loss :3.41916\n",
      "              Validation_loss :3.81021\n",
      "Epoch :49----> Train_loss :3.42259\n",
      "              Validation_loss :3.82973\n",
      "Epoch :50----> Train_loss :3.42665\n",
      "Saved weights at step 51\n",
      "              Validation_loss :3.81221\n",
      "Epoch :51----> Train_loss :3.42068\n",
      "              Validation_loss :3.82545\n",
      "Epoch :52----> Train_loss :3.42646\n",
      "              Validation_loss :3.80393\n",
      "Epoch :53----> Train_loss :3.41930\n",
      "              Validation_loss :3.79341\n",
      "Epoch :54----> Train_loss :3.41528\n",
      "              Validation_loss :3.83553\n",
      "Epoch :55----> Train_loss :3.42698\n",
      "              Validation_loss :3.80696\n",
      "Epoch :56----> Train_loss :3.41486\n",
      "              Validation_loss :3.80946\n",
      "Epoch :57----> Train_loss :3.41983\n",
      "              Validation_loss :3.84157\n",
      "Epoch :58----> Train_loss :3.42685\n",
      "              Validation_loss :3.79335\n",
      "Epoch :59----> Train_loss :3.40891\n",
      "              Validation_loss :3.80835\n",
      "Epoch :60----> Train_loss :3.41785\n",
      "              Validation_loss :3.83171\n",
      "Epoch :61----> Train_loss :3.42346\n",
      "              Validation_loss :3.79543\n",
      "Epoch :62----> Train_loss :3.40774\n",
      "              Validation_loss :3.83329\n",
      "Epoch :63----> Train_loss :3.42221\n",
      "              Validation_loss :3.82818\n",
      "Epoch :64----> Train_loss :3.42001\n",
      "              Validation_loss :3.79088\n",
      "Epoch :65----> Train_loss :3.41213\n",
      "              Validation_loss :3.82638\n",
      "Epoch :66----> Train_loss :3.42368\n",
      "              Validation_loss :3.80903\n",
      "Epoch :67----> Train_loss :3.41247\n",
      "              Validation_loss :3.81445\n",
      "Epoch :68----> Train_loss :3.41070\n",
      "              Validation_loss :3.87002\n",
      "Epoch :69----> Train_loss :3.42676\n",
      "              Validation_loss :3.80628\n",
      "Epoch :70----> Train_loss :3.40936\n",
      "              Validation_loss :3.80024\n",
      "Epoch :71----> Train_loss :3.40953\n",
      "              Validation_loss :3.82487\n",
      "Epoch :72----> Train_loss :3.42415\n",
      "              Validation_loss :3.79616\n",
      "Epoch :73----> Train_loss :3.40441\n",
      "              Validation_loss :3.84058\n",
      "Epoch :74----> Train_loss :3.41355\n",
      "              Validation_loss :3.85258\n",
      "Epoch :75----> Train_loss :3.42027\n",
      "              Validation_loss :3.79939\n",
      "Epoch :76----> Train_loss :3.40461\n",
      "              Validation_loss :3.81175\n",
      "Epoch :77----> Train_loss :3.41308\n",
      "              Validation_loss :3.81208\n",
      "Epoch :78----> Train_loss :3.41726\n",
      "              Validation_loss :3.80813\n",
      "Epoch :79----> Train_loss :3.40609\n",
      "              Validation_loss :3.86280\n",
      "Epoch :80----> Train_loss :3.42170\n",
      "              Validation_loss :3.84299\n",
      "Epoch :81----> Train_loss :3.41464\n",
      "              Validation_loss :3.79718\n",
      "Epoch :82----> Train_loss :3.40259\n",
      "              Validation_loss :3.82125\n",
      "Epoch :83----> Train_loss :3.41905\n",
      "              Validation_loss :3.79479\n",
      "Epoch :84----> Train_loss :3.40794\n",
      "              Validation_loss :3.82707\n",
      "Epoch :85----> Train_loss :3.40523\n",
      "              Validation_loss :3.88297\n",
      "Epoch :86----> Train_loss :3.42248\n",
      "              Validation_loss :3.82551\n",
      "Epoch :87----> Train_loss :3.40881\n",
      "              Validation_loss :3.79716\n",
      "Epoch :88----> Train_loss :3.40305\n",
      "              Validation_loss :3.82127\n",
      "Epoch :89----> Train_loss :3.41848\n",
      "              Validation_loss :3.80467\n",
      "Epoch :90----> Train_loss :3.40599\n",
      "              Validation_loss :3.83842\n",
      "Epoch :91----> Train_loss :3.40797\n",
      "              Validation_loss :3.88083\n",
      "Epoch :92----> Train_loss :3.42260\n",
      "              Validation_loss :3.80709\n",
      "Epoch :93----> Train_loss :3.40619\n",
      "              Validation_loss :3.80149\n",
      "Epoch :94----> Train_loss :3.40623\n",
      "              Validation_loss :3.82096\n",
      "Epoch :95----> Train_loss :3.41815\n",
      "              Validation_loss :3.79206\n",
      "Epoch :96----> Train_loss :3.40631\n",
      "              Validation_loss :3.83468\n",
      "Epoch :97----> Train_loss :3.40606\n",
      "              Validation_loss :3.87854\n",
      "Epoch :98----> Train_loss :3.41944\n",
      "              Validation_loss :3.81941\n",
      "Epoch :99----> Train_loss :3.40791\n",
      "              Validation_loss :3.80873\n"
     ]
    }
   ],
   "source": [
    "train_inputs=list(train_data['Features'].values)\n",
    "train_outputs=list(train_data['Targets'].values)\n",
    "val_inputs=list(val_data['Features'].values)\n",
    "val_outputs=list(val_data['Targets'].values)\n",
    "\n",
    "\n",
    "class TranformerModel(nn.Module):\n",
    "    def __init__(self,bert_model,vocab_size):\n",
    "        super(TranformerModel,self).__init__()\n",
    "        self.bert=bert_model\n",
    "        self.decoder=nn.Linear(768,vocab_size)\n",
    "        \n",
    "    def forward(self,input_ids,attention_mask):\n",
    "        outputs=self.bert(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        last_hidden_state=outputs.last_hidden_state\n",
    "        logits=self.decoder(last_hidden_state)\n",
    "        return logits\n",
    "    \n",
    "model=TranformerModel(bert,tokenizer.vocab_size)\n",
    "learning_rate=0.003849405145532908\n",
    "optimizer=AdamW(model.parameters(),lr=learning_rate)\n",
    "criterion=nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "\n",
    "epochs=100\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    model.train()\n",
    "    total_loss=0\n",
    "    for i in range(0,len(train_inputs)):\n",
    "        train_input_ids=train_inputs[i]['input_ids'].to(device)\n",
    "        train_attention_mask = train_inputs[i]['attention_mask'].to(device)\n",
    "        train_output_ids = train_outputs[i]['input_ids'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits=model(train_input_ids,train_attention_mask)\n",
    "        loss=criterion(logits.view(-1,logits.size(-1)),train_output_ids.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=loss.item()\n",
    "    \n",
    "    avg_loss=total_loss/len(train_inputs)\n",
    "    print(f'Epoch :{epoch}----> Train_loss :{avg_loss:.5f}')\n",
    "    if epoch%50==0:\n",
    "        weights_path=os.path.join(output_dir,f'weights_step_{epoch+1}.pth')\n",
    "        torch.save(model.state_dict(),weights_path)\n",
    "        print(f'Saved weights at step {epoch+1}')\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss=0\n",
    "    with torch.no_grad():\n",
    "        for i in range(0,len(val_inputs)):\n",
    "            val_input_ids=val_inputs[i]['input_ids'].to(device)\n",
    "            val_attention_mask = val_inputs[i]['attention_mask'].to(device)\n",
    "            val_output_ids = val_outputs[i]['input_ids'].to(device)\n",
    "            \n",
    "            logits=model(val_input_ids,val_attention_mask)\n",
    "            loss=criterion(logits.view(-1,logits.size(-1)),val_output_ids.view(-1))\n",
    "            val_loss+=loss.item()\n",
    "            \n",
    "        avg_val_loss=val_loss/len(val_inputs)\n",
    "        print(f'              Validation_loss :{avg_val_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\DELL\\\\Documents\\\\ML4SCI\\\\bert-with-genalgo-model.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "model_dir=r'C:\\Users\\DELL\\Documents\\ML4SCI\\bert-with-genalgo-model.joblib'\n",
    "joblib.dump(model,model_dir)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 6885392,
     "sourceId": 11052016,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6888231,
     "sourceId": 11056160,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
